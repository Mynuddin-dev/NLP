{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e62ad8fa",
   "metadata": {},
   "source": [
    "- [Word2Vec Explained](https://israelg99.github.io/2017-03-23-Word2Vec-Explained/)\n",
    "- [Word2vec WikiPidea](https://en.wikipedia.org/wiki/Word2vec#Dimensionality)\n",
    "\n",
    "- [What is Word2Vec? A Simple Explanation ](https://www.youtube.com/watch?v=hQwFeIupNP0)\n",
    "- [Word2Vec - Skipgram and CBOW YOU TUBE](https://www.youtube.com/watch?v=UqRCEmrv1gQ)\n",
    "\n",
    "- Each word Basically represent as a vector of 32 or more dimension instead of single number\n",
    "- Here the semantic information and relation between two words also preserve\n",
    "- [Gensim word2vec](https://radimrehurek.com/gensim/models/word2vec.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10948e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import word2vec , keyedvectors\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168b6b0a",
   "metadata": {},
   "source": [
    "### Reading and Exploring the Dataset\n",
    "The dataset we are using here is a subset of Amazon reviews from the Cell Phones & Accessories category. The data is stored as a JSON file and can be read using pandas.\n",
    "\n",
    "Link to the Dataset: http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Cell_Phones_and_Accessories_5.json.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb073e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c0c0a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c119ed96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A30TL5EWN6DFXT</td>\n",
       "      <td>120401325X</td>\n",
       "      <td>christina</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>They look good and stick good! I just don't li...</td>\n",
       "      <td>4</td>\n",
       "      <td>Looks Good</td>\n",
       "      <td>1400630400</td>\n",
       "      <td>05 21, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASY55RVNIL0UD</td>\n",
       "      <td>120401325X</td>\n",
       "      <td>emily l.</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>These stickers work like the review says they ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Really great product.</td>\n",
       "      <td>1389657600</td>\n",
       "      <td>01 14, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A2TMXE2AFO7ONB</td>\n",
       "      <td>120401325X</td>\n",
       "      <td>Erica</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>These are awesome and make my phone look so st...</td>\n",
       "      <td>5</td>\n",
       "      <td>LOVE LOVE LOVE</td>\n",
       "      <td>1403740800</td>\n",
       "      <td>06 26, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AWJ0WZQYMYFQ4</td>\n",
       "      <td>120401325X</td>\n",
       "      <td>JM</td>\n",
       "      <td>[4, 4]</td>\n",
       "      <td>Item arrived in great time and was in perfect ...</td>\n",
       "      <td>4</td>\n",
       "      <td>Cute!</td>\n",
       "      <td>1382313600</td>\n",
       "      <td>10 21, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ATX7CZYFXI1KW</td>\n",
       "      <td>120401325X</td>\n",
       "      <td>patrice m rogoza</td>\n",
       "      <td>[2, 3]</td>\n",
       "      <td>awesome! stays on, and looks great. can be use...</td>\n",
       "      <td>5</td>\n",
       "      <td>leopard home button sticker for iphone 4s</td>\n",
       "      <td>1359849600</td>\n",
       "      <td>02 3, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194434</th>\n",
       "      <td>A1YMNTFLNDYQ1F</td>\n",
       "      <td>B00LORXVUE</td>\n",
       "      <td>eyeused2loveher</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Works great just like my original one. I reall...</td>\n",
       "      <td>5</td>\n",
       "      <td>This works just perfect!</td>\n",
       "      <td>1405900800</td>\n",
       "      <td>07 21, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194435</th>\n",
       "      <td>A15TX8B2L8B20S</td>\n",
       "      <td>B00LORXVUE</td>\n",
       "      <td>Jon Davidson</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Great product. Great packaging. High quality a...</td>\n",
       "      <td>5</td>\n",
       "      <td>Great replacement cable. Apple certified</td>\n",
       "      <td>1405900800</td>\n",
       "      <td>07 21, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194436</th>\n",
       "      <td>A3JI7QRZO1QG8X</td>\n",
       "      <td>B00LORXVUE</td>\n",
       "      <td>Joyce M. Davidson</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>This is a great cable, just as good as the mor...</td>\n",
       "      <td>5</td>\n",
       "      <td>Real quality</td>\n",
       "      <td>1405900800</td>\n",
       "      <td>07 21, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194437</th>\n",
       "      <td>A1NHB2VC68YQNM</td>\n",
       "      <td>B00LORXVUE</td>\n",
       "      <td>Nurse Farrugia</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>I really like it becasue it works well with my...</td>\n",
       "      <td>5</td>\n",
       "      <td>I really like it becasue it works well with my...</td>\n",
       "      <td>1405814400</td>\n",
       "      <td>07 20, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194438</th>\n",
       "      <td>A1AG6U022WHXBF</td>\n",
       "      <td>B00LORXVUE</td>\n",
       "      <td>Trisha Crocker</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>product as described, I have wasted a lot of m...</td>\n",
       "      <td>5</td>\n",
       "      <td>I have wasted a lot of money on cords</td>\n",
       "      <td>1405900800</td>\n",
       "      <td>07 21, 2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>194439 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            reviewerID        asin       reviewerName helpful  \\\n",
       "0       A30TL5EWN6DFXT  120401325X          christina  [0, 0]   \n",
       "1        ASY55RVNIL0UD  120401325X           emily l.  [0, 0]   \n",
       "2       A2TMXE2AFO7ONB  120401325X              Erica  [0, 0]   \n",
       "3        AWJ0WZQYMYFQ4  120401325X                 JM  [4, 4]   \n",
       "4        ATX7CZYFXI1KW  120401325X   patrice m rogoza  [2, 3]   \n",
       "...                ...         ...                ...     ...   \n",
       "194434  A1YMNTFLNDYQ1F  B00LORXVUE    eyeused2loveher  [0, 0]   \n",
       "194435  A15TX8B2L8B20S  B00LORXVUE       Jon Davidson  [0, 0]   \n",
       "194436  A3JI7QRZO1QG8X  B00LORXVUE  Joyce M. Davidson  [0, 0]   \n",
       "194437  A1NHB2VC68YQNM  B00LORXVUE     Nurse Farrugia  [0, 0]   \n",
       "194438  A1AG6U022WHXBF  B00LORXVUE     Trisha Crocker  [0, 0]   \n",
       "\n",
       "                                               reviewText  overall  \\\n",
       "0       They look good and stick good! I just don't li...        4   \n",
       "1       These stickers work like the review says they ...        5   \n",
       "2       These are awesome and make my phone look so st...        5   \n",
       "3       Item arrived in great time and was in perfect ...        4   \n",
       "4       awesome! stays on, and looks great. can be use...        5   \n",
       "...                                                   ...      ...   \n",
       "194434  Works great just like my original one. I reall...        5   \n",
       "194435  Great product. Great packaging. High quality a...        5   \n",
       "194436  This is a great cable, just as good as the mor...        5   \n",
       "194437  I really like it becasue it works well with my...        5   \n",
       "194438  product as described, I have wasted a lot of m...        5   \n",
       "\n",
       "                                                  summary  unixReviewTime  \\\n",
       "0                                              Looks Good      1400630400   \n",
       "1                                   Really great product.      1389657600   \n",
       "2                                          LOVE LOVE LOVE      1403740800   \n",
       "3                                                   Cute!      1382313600   \n",
       "4               leopard home button sticker for iphone 4s      1359849600   \n",
       "...                                                   ...             ...   \n",
       "194434                           This works just perfect!      1405900800   \n",
       "194435           Great replacement cable. Apple certified      1405900800   \n",
       "194436                                       Real quality      1405900800   \n",
       "194437  I really like it becasue it works well with my...      1405814400   \n",
       "194438              I have wasted a lot of money on cords      1405900800   \n",
       "\n",
       "         reviewTime  \n",
       "0       05 21, 2014  \n",
       "1       01 14, 2014  \n",
       "2       06 26, 2014  \n",
       "3       10 21, 2013  \n",
       "4        02 3, 2013  \n",
       "...             ...  \n",
       "194434  07 21, 2014  \n",
       "194435  07 21, 2014  \n",
       "194436  07 21, 2014  \n",
       "194437  07 20, 2014  \n",
       "194438  07 21, 2014  \n",
       "\n",
       "[194439 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = pd.read_json(\"reviews_cell_phones_and_accessories_5.json\", lines=True)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "940a8aca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"They look good and stick good! I just don't like the rounded shape because I was always bumping it and Siri kept popping up and it was irritating. I just won't buy a product like this again\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.reviewText[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631240bb",
   "metadata": {},
   "source": [
    "\n",
    "### Simple Preprocessing & Tokenization\n",
    "The first thing to do for any data science task is to clean the data. For NLP, we apply various processing like converting all the words to lower case, trimming spaces, removing punctuations. This is something we will do over here too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "957929c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         [they, look, good, and, stick, good, just, don...\n",
       "1         [these, stickers, work, like, the, review, say...\n",
       "2         [these, are, awesome, and, make, my, phone, lo...\n",
       "3         [item, arrived, in, great, time, and, was, in,...\n",
       "4         [awesome, stays, on, and, looks, great, can, b...\n",
       "                                ...                        \n",
       "194434    [works, great, just, like, my, original, one, ...\n",
       "194435    [great, product, great, packaging, high, quali...\n",
       "194436    [this, is, great, cable, just, as, good, as, t...\n",
       "194437    [really, like, it, becasue, it, works, well, w...\n",
       "194438    [product, as, described, have, wasted, lot, of...\n",
       "Name: reviewText, Length: 194439, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_text = df.reviewText.apply(gensim.utils.simple_preprocess)\n",
    "review_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31524067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['they',\n",
       " 'look',\n",
       " 'good',\n",
       " 'and',\n",
       " 'stick',\n",
       " 'good',\n",
       " 'just',\n",
       " 'don',\n",
       " 'like',\n",
       " 'the',\n",
       " 'rounded',\n",
       " 'shape',\n",
       " 'because',\n",
       " 'was',\n",
       " 'always',\n",
       " 'bumping',\n",
       " 'it',\n",
       " 'and',\n",
       " 'siri',\n",
       " 'kept',\n",
       " 'popping',\n",
       " 'up',\n",
       " 'and',\n",
       " 'it',\n",
       " 'was',\n",
       " 'irritating',\n",
       " 'just',\n",
       " 'won',\n",
       " 'buy',\n",
       " 'product',\n",
       " 'like',\n",
       " 'this',\n",
       " 'again']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_text[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a80dd1d",
   "metadata": {},
   "source": [
    "### Training the Word2Vec Model\n",
    "Train the model for reviews. Use a window of size 10 i.e. 10 words before the present word and 10 words ahead. A sentence with at least 2 words should only be considered, configure this using min_count parameter.\n",
    "\n",
    "Workers define how many CPU threads to be used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745f9a0f",
   "metadata": {},
   "source": [
    "#### Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb9c37af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = gensim.models.Word2Vec(\n",
    "    window=10,\n",
    "    min_count=2,\n",
    "    workers=4,\n",
    ")\n",
    "\n",
    "# sg: (default 0 or CBOW) The training algorithm, either CBOW (0) or skip gram (1)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227a6665",
   "metadata": {},
   "source": [
    "#### Build Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8cd927b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.build_vocab(review_text, progress_per=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c92a7db4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e7eaab8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "194439"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.corpus_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dcd0d601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(194439, 9)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "371dc7e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61508184, 83868975)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(review_text, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "077b2c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./word2vec-amazon-cell-accessories-reviews-short.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "103f102a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('woman', 0.7144899368286133),\n",
       " ('girl', 0.6376656889915466),\n",
       " ('guy', 0.6234941482543945),\n",
       " ('women', 0.6160207986831665),\n",
       " ('student', 0.5694995522499084),\n",
       " ('young', 0.5678049325942993),\n",
       " ('men', 0.567389190196991),\n",
       " ('boy', 0.5562182664871216),\n",
       " ('lbs', 0.5527745485305786),\n",
       " ('toy', 0.5512212514877319)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"man\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5fbbb532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.51627254"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity(w1=\"cheap\", w2=\"inexpensive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b5f50d3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity(w1=\"cheap\", w2=\"cheap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "437203c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.779374"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity(w1=\"great\", w2=\"good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530b274a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "886a3844",
   "metadata": {},
   "source": [
    "### Another Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "364aa25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a350bca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph = \"\"\"I have three visions for India. In 3000 years of our history, people from all over \n",
    "               the world have come and invaded us, captured our lands, conquered our minds. \n",
    "               From Alexander onwards, the Greeks, the Turks, the Moguls, the Portuguese, the British,\n",
    "               the French, the Dutch, all of them came and looted us, took over what was ours. \n",
    "               Yet we have not done this to any other nation. We have not conquered anyone. \n",
    "               We have not grabbed their land, their culture, \n",
    "               their history and tried to enforce our way of life on them. \n",
    "               Why? Because we respect the freedom of others.That is why my \n",
    "               first vision is that of freedom. I believe that India got its first vision of \n",
    "               this in 1857, when we started the War of Independence. It is this freedom that\n",
    "               we must protect and nurture and build on. If we are not free, no one will respect us.\n",
    "               My second vision for Indiaâ€™s development. For fifty years we have been a developing nation.\n",
    "               It is time we see ourselves as a developed nation. We are among the top 5 nations of the world\n",
    "               in terms of GDP. We have a 10 percent growth rate in most areas. Our poverty levels are falling.\n",
    "               Our achievements are being globally recognised today. Yet we lack the self-confidence to\n",
    "               see ourselves as a developed nation, self-reliant and self-assured. Isnâ€™t this incorrect?\n",
    "               I have a third vision. India must stand up to the world. Because I believe that unless India \n",
    "               stands up to the world, no one will respect us. Only strength respects strength. We must be \n",
    "               strong not only as a military power but also as an economic power. Both must go hand-in-hand. \n",
    "               My good fortune was to have worked with three great minds. Dr. Vikram Sarabhai of the Dept. of \n",
    "               space, Professor Satish Dhawan, who succeeded him and Dr. Brahm Prakash, father of nuclear material.\n",
    "               I was lucky to have worked with all three of them closely and consider this the great opportunity of my life. \n",
    "               I see four milestones in my career\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "046c701f",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_paragraph = paragraph.lower()\n",
    "processed_paragraph = re.sub('[^a-zA-Z]', ' ', processed_paragraph)\n",
    "processed_paragraph = re.sub(r'\\s+', ' ', processed_paragraph)\n",
    "\n",
    "# Preparing the dataset\n",
    "all_sentences = nltk.sent_tokenize(processed_paragraph)\n",
    "\n",
    "all_words = [nltk.word_tokenize(sent) for sent in all_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6804ed4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['i',\n",
       "  'have',\n",
       "  'three',\n",
       "  'visions',\n",
       "  'for',\n",
       "  'india',\n",
       "  'in',\n",
       "  'years',\n",
       "  'of',\n",
       "  'our',\n",
       "  'history',\n",
       "  'people',\n",
       "  'from',\n",
       "  'all',\n",
       "  'over',\n",
       "  'the',\n",
       "  'world',\n",
       "  'have',\n",
       "  'come',\n",
       "  'and',\n",
       "  'invaded',\n",
       "  'us',\n",
       "  'captured',\n",
       "  'our',\n",
       "  'lands',\n",
       "  'conquered',\n",
       "  'our',\n",
       "  'minds',\n",
       "  'from',\n",
       "  'alexander',\n",
       "  'onwards',\n",
       "  'the',\n",
       "  'greeks',\n",
       "  'the',\n",
       "  'turks',\n",
       "  'the',\n",
       "  'moguls',\n",
       "  'the',\n",
       "  'portuguese',\n",
       "  'the',\n",
       "  'british',\n",
       "  'the',\n",
       "  'french',\n",
       "  'the',\n",
       "  'dutch',\n",
       "  'all',\n",
       "  'of',\n",
       "  'them',\n",
       "  'came',\n",
       "  'and',\n",
       "  'looted',\n",
       "  'us',\n",
       "  'took',\n",
       "  'over',\n",
       "  'what',\n",
       "  'was',\n",
       "  'ours',\n",
       "  'yet',\n",
       "  'we',\n",
       "  'have',\n",
       "  'not',\n",
       "  'done',\n",
       "  'this',\n",
       "  'to',\n",
       "  'any',\n",
       "  'other',\n",
       "  'nation',\n",
       "  'we',\n",
       "  'have',\n",
       "  'not',\n",
       "  'conquered',\n",
       "  'anyone',\n",
       "  'we',\n",
       "  'have',\n",
       "  'not',\n",
       "  'grabbed',\n",
       "  'their',\n",
       "  'land',\n",
       "  'their',\n",
       "  'culture',\n",
       "  'their',\n",
       "  'history',\n",
       "  'and',\n",
       "  'tried',\n",
       "  'to',\n",
       "  'enforce',\n",
       "  'our',\n",
       "  'way',\n",
       "  'of',\n",
       "  'life',\n",
       "  'on',\n",
       "  'them',\n",
       "  'why',\n",
       "  'because',\n",
       "  'we',\n",
       "  'respect',\n",
       "  'the',\n",
       "  'freedom',\n",
       "  'of',\n",
       "  'others',\n",
       "  'that',\n",
       "  'is',\n",
       "  'why',\n",
       "  'my',\n",
       "  'first',\n",
       "  'vision',\n",
       "  'is',\n",
       "  'that',\n",
       "  'of',\n",
       "  'freedom',\n",
       "  'i',\n",
       "  'believe',\n",
       "  'that',\n",
       "  'india',\n",
       "  'got',\n",
       "  'its',\n",
       "  'first',\n",
       "  'vision',\n",
       "  'of',\n",
       "  'this',\n",
       "  'in',\n",
       "  'when',\n",
       "  'we',\n",
       "  'started',\n",
       "  'the',\n",
       "  'war',\n",
       "  'of',\n",
       "  'independence',\n",
       "  'it',\n",
       "  'is',\n",
       "  'this',\n",
       "  'freedom',\n",
       "  'that',\n",
       "  'we',\n",
       "  'must',\n",
       "  'protect',\n",
       "  'and',\n",
       "  'nurture',\n",
       "  'and',\n",
       "  'build',\n",
       "  'on',\n",
       "  'if',\n",
       "  'we',\n",
       "  'are',\n",
       "  'not',\n",
       "  'free',\n",
       "  'no',\n",
       "  'one',\n",
       "  'will',\n",
       "  'respect',\n",
       "  'us',\n",
       "  'my',\n",
       "  'second',\n",
       "  'vision',\n",
       "  'for',\n",
       "  'india',\n",
       "  's',\n",
       "  'development',\n",
       "  'for',\n",
       "  'fifty',\n",
       "  'years',\n",
       "  'we',\n",
       "  'have',\n",
       "  'been',\n",
       "  'a',\n",
       "  'developing',\n",
       "  'nation',\n",
       "  'it',\n",
       "  'is',\n",
       "  'time',\n",
       "  'we',\n",
       "  'see',\n",
       "  'ourselves',\n",
       "  'as',\n",
       "  'a',\n",
       "  'developed',\n",
       "  'nation',\n",
       "  'we',\n",
       "  'are',\n",
       "  'among',\n",
       "  'the',\n",
       "  'top',\n",
       "  'nations',\n",
       "  'of',\n",
       "  'the',\n",
       "  'world',\n",
       "  'in',\n",
       "  'terms',\n",
       "  'of',\n",
       "  'gdp',\n",
       "  'we',\n",
       "  'have',\n",
       "  'a',\n",
       "  'percent',\n",
       "  'growth',\n",
       "  'rate',\n",
       "  'in',\n",
       "  'most',\n",
       "  'areas',\n",
       "  'our',\n",
       "  'poverty',\n",
       "  'levels',\n",
       "  'are',\n",
       "  'falling',\n",
       "  'our',\n",
       "  'achievements',\n",
       "  'are',\n",
       "  'being',\n",
       "  'globally',\n",
       "  'recognised',\n",
       "  'today',\n",
       "  'yet',\n",
       "  'we',\n",
       "  'lack',\n",
       "  'the',\n",
       "  'self',\n",
       "  'confidence',\n",
       "  'to',\n",
       "  'see',\n",
       "  'ourselves',\n",
       "  'as',\n",
       "  'a',\n",
       "  'developed',\n",
       "  'nation',\n",
       "  'self',\n",
       "  'reliant',\n",
       "  'and',\n",
       "  'self',\n",
       "  'assured',\n",
       "  'isn',\n",
       "  't',\n",
       "  'this',\n",
       "  'incorrect',\n",
       "  'i',\n",
       "  'have',\n",
       "  'a',\n",
       "  'third',\n",
       "  'vision',\n",
       "  'india',\n",
       "  'must',\n",
       "  'stand',\n",
       "  'up',\n",
       "  'to',\n",
       "  'the',\n",
       "  'world',\n",
       "  'because',\n",
       "  'i',\n",
       "  'believe',\n",
       "  'that',\n",
       "  'unless',\n",
       "  'india',\n",
       "  'stands',\n",
       "  'up',\n",
       "  'to',\n",
       "  'the',\n",
       "  'world',\n",
       "  'no',\n",
       "  'one',\n",
       "  'will',\n",
       "  'respect',\n",
       "  'us',\n",
       "  'only',\n",
       "  'strength',\n",
       "  'respects',\n",
       "  'strength',\n",
       "  'we',\n",
       "  'must',\n",
       "  'be',\n",
       "  'strong',\n",
       "  'not',\n",
       "  'only',\n",
       "  'as',\n",
       "  'a',\n",
       "  'military',\n",
       "  'power',\n",
       "  'but',\n",
       "  'also',\n",
       "  'as',\n",
       "  'an',\n",
       "  'economic',\n",
       "  'power',\n",
       "  'both',\n",
       "  'must',\n",
       "  'go',\n",
       "  'hand',\n",
       "  'in',\n",
       "  'hand',\n",
       "  'my',\n",
       "  'good',\n",
       "  'fortune',\n",
       "  'was',\n",
       "  'to',\n",
       "  'have',\n",
       "  'worked',\n",
       "  'with',\n",
       "  'three',\n",
       "  'great',\n",
       "  'minds',\n",
       "  'dr',\n",
       "  'vikram',\n",
       "  'sarabhai',\n",
       "  'of',\n",
       "  'the',\n",
       "  'dept',\n",
       "  'of',\n",
       "  'space',\n",
       "  'professor',\n",
       "  'satish',\n",
       "  'dhawan',\n",
       "  'who',\n",
       "  'succeeded',\n",
       "  'him',\n",
       "  'and',\n",
       "  'dr',\n",
       "  'brahm',\n",
       "  'prakash',\n",
       "  'father',\n",
       "  'of',\n",
       "  'nuclear',\n",
       "  'material',\n",
       "  'i',\n",
       "  'was',\n",
       "  'lucky',\n",
       "  'to',\n",
       "  'have',\n",
       "  'worked',\n",
       "  'with',\n",
       "  'all',\n",
       "  'three',\n",
       "  'of',\n",
       "  'them',\n",
       "  'closely',\n",
       "  'and',\n",
       "  'consider',\n",
       "  'this',\n",
       "  'the',\n",
       "  'great',\n",
       "  'opportunity',\n",
       "  'of',\n",
       "  'my',\n",
       "  'life',\n",
       "  'i',\n",
       "  'see',\n",
       "  'four',\n",
       "  'milestones',\n",
       "  'in',\n",
       "  'my',\n",
       "  'career']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb620cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing Stop Words\n",
    "from nltk.corpus import stopwords\n",
    "for i in range(len(all_words)):\n",
    "    all_words[i] = [word for word in all_words[i] if word not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c14a0302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['three',\n",
       "  'visions',\n",
       "  'india',\n",
       "  'years',\n",
       "  'history',\n",
       "  'people',\n",
       "  'world',\n",
       "  'come',\n",
       "  'invaded',\n",
       "  'us',\n",
       "  'captured',\n",
       "  'lands',\n",
       "  'conquered',\n",
       "  'minds',\n",
       "  'alexander',\n",
       "  'onwards',\n",
       "  'greeks',\n",
       "  'turks',\n",
       "  'moguls',\n",
       "  'portuguese',\n",
       "  'british',\n",
       "  'french',\n",
       "  'dutch',\n",
       "  'came',\n",
       "  'looted',\n",
       "  'us',\n",
       "  'took',\n",
       "  'yet',\n",
       "  'done',\n",
       "  'nation',\n",
       "  'conquered',\n",
       "  'anyone',\n",
       "  'grabbed',\n",
       "  'land',\n",
       "  'culture',\n",
       "  'history',\n",
       "  'tried',\n",
       "  'enforce',\n",
       "  'way',\n",
       "  'life',\n",
       "  'respect',\n",
       "  'freedom',\n",
       "  'others',\n",
       "  'first',\n",
       "  'vision',\n",
       "  'freedom',\n",
       "  'believe',\n",
       "  'india',\n",
       "  'got',\n",
       "  'first',\n",
       "  'vision',\n",
       "  'started',\n",
       "  'war',\n",
       "  'independence',\n",
       "  'freedom',\n",
       "  'must',\n",
       "  'protect',\n",
       "  'nurture',\n",
       "  'build',\n",
       "  'free',\n",
       "  'one',\n",
       "  'respect',\n",
       "  'us',\n",
       "  'second',\n",
       "  'vision',\n",
       "  'india',\n",
       "  'development',\n",
       "  'fifty',\n",
       "  'years',\n",
       "  'developing',\n",
       "  'nation',\n",
       "  'time',\n",
       "  'see',\n",
       "  'developed',\n",
       "  'nation',\n",
       "  'among',\n",
       "  'top',\n",
       "  'nations',\n",
       "  'world',\n",
       "  'terms',\n",
       "  'gdp',\n",
       "  'percent',\n",
       "  'growth',\n",
       "  'rate',\n",
       "  'areas',\n",
       "  'poverty',\n",
       "  'levels',\n",
       "  'falling',\n",
       "  'achievements',\n",
       "  'globally',\n",
       "  'recognised',\n",
       "  'today',\n",
       "  'yet',\n",
       "  'lack',\n",
       "  'self',\n",
       "  'confidence',\n",
       "  'see',\n",
       "  'developed',\n",
       "  'nation',\n",
       "  'self',\n",
       "  'reliant',\n",
       "  'self',\n",
       "  'assured',\n",
       "  'incorrect',\n",
       "  'third',\n",
       "  'vision',\n",
       "  'india',\n",
       "  'must',\n",
       "  'stand',\n",
       "  'world',\n",
       "  'believe',\n",
       "  'unless',\n",
       "  'india',\n",
       "  'stands',\n",
       "  'world',\n",
       "  'one',\n",
       "  'respect',\n",
       "  'us',\n",
       "  'strength',\n",
       "  'respects',\n",
       "  'strength',\n",
       "  'must',\n",
       "  'strong',\n",
       "  'military',\n",
       "  'power',\n",
       "  'also',\n",
       "  'economic',\n",
       "  'power',\n",
       "  'must',\n",
       "  'go',\n",
       "  'hand',\n",
       "  'hand',\n",
       "  'good',\n",
       "  'fortune',\n",
       "  'worked',\n",
       "  'three',\n",
       "  'great',\n",
       "  'minds',\n",
       "  'dr',\n",
       "  'vikram',\n",
       "  'sarabhai',\n",
       "  'dept',\n",
       "  'space',\n",
       "  'professor',\n",
       "  'satish',\n",
       "  'dhawan',\n",
       "  'succeeded',\n",
       "  'dr',\n",
       "  'brahm',\n",
       "  'prakash',\n",
       "  'father',\n",
       "  'nuclear',\n",
       "  'material',\n",
       "  'lucky',\n",
       "  'worked',\n",
       "  'three',\n",
       "  'closely',\n",
       "  'consider',\n",
       "  'great',\n",
       "  'opportunity',\n",
       "  'life',\n",
       "  'see',\n",
       "  'four',\n",
       "  'milestones',\n",
       "  'career']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b835dd0",
   "metadata": {},
   "source": [
    "### Creating Word2Vec Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cae32ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(all_words, min_count=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "366212e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding Word Vectors\n",
    "vector = model.wv['see']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "05ab6b5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-9.58062708e-03,  8.96992814e-03,  4.17919783e-03,  9.26031265e-03,\n",
       "        6.64846459e-03,  2.91303615e-03,  9.83883068e-03, -4.40194784e-03,\n",
       "       -6.83826813e-03,  4.20083292e-03,  3.73480050e-03, -5.68703748e-03,\n",
       "        9.72128659e-03, -3.56320175e-03,  9.55601316e-03,  8.33498780e-04,\n",
       "       -6.30994933e-03, -1.98007398e-03, -7.39609497e-03, -3.03064659e-03,\n",
       "        1.04605174e-03,  9.49276332e-03,  9.37271584e-03, -6.62563136e-03,\n",
       "        3.45783960e-03,  2.27852142e-03, -2.50939489e-03, -9.22383461e-03,\n",
       "        1.03023998e-03, -8.15419760e-03,  6.33127009e-03, -5.81249176e-03,\n",
       "        5.53191779e-03,  9.82042495e-03, -1.82000702e-04,  4.54787537e-03,\n",
       "       -1.80061534e-03,  7.36754015e-03,  3.93243926e-03, -9.01106931e-03,\n",
       "       -2.36555771e-03,  3.61610227e-03, -1.03208884e-04, -1.19464030e-03,\n",
       "       -1.04304112e-03, -1.67205918e-03,  5.97835984e-04,  4.15182533e-03,\n",
       "       -4.24516387e-03, -3.82727943e-03, -3.96006581e-05,  2.60016386e-04,\n",
       "       -1.65811914e-04, -4.79019294e-03,  4.29329649e-03, -2.16846587e-03,\n",
       "        2.12235679e-03,  6.63590152e-04,  5.96231408e-03, -6.84936671e-03,\n",
       "       -6.82395883e-03, -4.49910201e-03,  9.45811346e-03, -1.58673327e-03,\n",
       "       -9.43816453e-03, -5.06696582e-04, -4.45284043e-03,  6.01137476e-03,\n",
       "       -9.61950794e-03,  2.85840966e-03, -9.26523097e-03,  1.25922158e-03,\n",
       "        6.02855394e-03,  7.40410155e-03, -7.62851303e-03, -6.05584122e-03,\n",
       "       -6.81921514e-03, -7.90585019e-03, -9.50117782e-03, -2.12089648e-03,\n",
       "       -8.57884763e-04, -7.25821359e-03,  6.78957021e-03,  1.11869641e-03,\n",
       "        5.84326359e-03,  1.45738292e-03,  8.00750044e-04, -7.36798858e-03,\n",
       "       -2.15426297e-03,  4.32999013e-03, -5.06707374e-03,  1.13348907e-03,\n",
       "        2.87420955e-03, -1.53729541e-03,  9.96232126e-03,  8.34249146e-03,\n",
       "        2.41905334e-03,  7.12095713e-03,  5.90886408e-03, -5.57277258e-03],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75a3011d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('world', 0.2029840648174286),\n",
       " ('believe', 0.09815169870853424),\n",
       " ('us', 0.07644196599721909),\n",
       " ('vision', 0.06272962689399719),\n",
       " ('freedom', 0.04679276421666145),\n",
       " ('years', 0.039732933044433594),\n",
       " ('first', 0.038035809993743896),\n",
       " ('nation', 0.03507174924015999),\n",
       " ('india', 0.032317694276571274),\n",
       " ('respect', 0.0273970328271389)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Most similar words\n",
    "similar = model.wv.most_similar(\"see\")\n",
    "similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ece4b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f90c34af",
   "metadata": {},
   "source": [
    "### Another Example\n",
    "- [Most Useful Article](https://stackabuse.com/implementing-word2vec-with-gensim-library-in-python/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a784854d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4 as bs\n",
    "import urllib.request\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "scrapped_data = urllib.request.urlopen('https://en.wikipedia.org/wiki/Artificial_intelligence')\n",
    "article = scrapped_data .read()\n",
    "\n",
    "parsed_article = bs.BeautifulSoup(article,'lxml')\n",
    "\n",
    "paragraphs = parsed_article.find_all('p')\n",
    "\n",
    "article_text = \"\"\n",
    "\n",
    "for p in paragraphs:\n",
    "    article_text += p.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881c0a04",
   "metadata": {},
   "source": [
    "- urllib library : We first download the Wikipedia article using the urlopen method\n",
    "- BeautifulSoup : We then read the article content and parse it using an object.\n",
    "- Wikipedia stores the text content of the article inside p tags. We use the find_all function of the BeautifulSoup object to fetch all the contents from the paragraph tags of the article.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9a00b3",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b93957dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaing the text\n",
    "processed_article = article_text.lower()\n",
    "processed_article = re.sub('[^a-zA-Z]', ' ', processed_article )\n",
    "processed_article = re.sub(r'\\s+', ' ', processed_article)\n",
    "\n",
    "# Preparing the dataset\n",
    "all_sentences = nltk.sent_tokenize(processed_article)\n",
    "\n",
    "all_words = [nltk.word_tokenize(sent) for sent in all_sentences]\n",
    "\n",
    "# Removing Stop Words\n",
    "from nltk.corpus import stopwords\n",
    "for i in range(len(all_words)):\n",
    "    all_words[i] = [word for word in all_words[i] if word not in stopwords.words('english')]\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "67384ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "word2vec = Word2Vec(all_words, min_count=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "24f90b8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['artificial',\n",
       "  'intelligence',\n",
       "  'ai',\n",
       "  'intelligence',\n",
       "  'demonstrated',\n",
       "  'machines',\n",
       "  'opposed',\n",
       "  'natural',\n",
       "  'intelligence',\n",
       "  'displayed',\n",
       "  'humans',\n",
       "  'animals',\n",
       "  'leading',\n",
       "  'ai',\n",
       "  'textbooks',\n",
       "  'define',\n",
       "  'field',\n",
       "  'study',\n",
       "  'intelligent',\n",
       "  'agents',\n",
       "  'system',\n",
       "  'perceives',\n",
       "  'environment',\n",
       "  'takes',\n",
       "  'actions',\n",
       "  'maximize',\n",
       "  'chance',\n",
       "  'achieving',\n",
       "  'goals',\n",
       "  'popular',\n",
       "  'accounts',\n",
       "  'use',\n",
       "  'term',\n",
       "  'artificial',\n",
       "  'intelligence',\n",
       "  'describe',\n",
       "  'machines',\n",
       "  'mimic',\n",
       "  'cognitive',\n",
       "  'functions',\n",
       "  'humans',\n",
       "  'associate',\n",
       "  'human',\n",
       "  'mind',\n",
       "  'learning',\n",
       "  'problem',\n",
       "  'solving',\n",
       "  'however',\n",
       "  'definition',\n",
       "  'rejected',\n",
       "  'major',\n",
       "  'ai',\n",
       "  'researchers',\n",
       "  'b',\n",
       "  'c',\n",
       "  'ai',\n",
       "  'applications',\n",
       "  'include',\n",
       "  'advanced',\n",
       "  'web',\n",
       "  'search',\n",
       "  'engines',\n",
       "  'e',\n",
       "  'google',\n",
       "  'recommendation',\n",
       "  'systems',\n",
       "  'used',\n",
       "  'youtube',\n",
       "  'amazon',\n",
       "  'netflix',\n",
       "  'understanding',\n",
       "  'human',\n",
       "  'speech',\n",
       "  'siri',\n",
       "  'alexa',\n",
       "  'self',\n",
       "  'driving',\n",
       "  'cars',\n",
       "  'e',\n",
       "  'g',\n",
       "  'tesla',\n",
       "  'competing',\n",
       "  'highest',\n",
       "  'level',\n",
       "  'strategic',\n",
       "  'game',\n",
       "  'systems',\n",
       "  'chess',\n",
       "  'go',\n",
       "  'machines',\n",
       "  'become',\n",
       "  'increasingly',\n",
       "  'capable',\n",
       "  'tasks',\n",
       "  'considered',\n",
       "  'require',\n",
       "  'intelligence',\n",
       "  'often',\n",
       "  'removed',\n",
       "  'definition',\n",
       "  'ai',\n",
       "  'phenomenon',\n",
       "  'known',\n",
       "  'ai',\n",
       "  'effect',\n",
       "  'instance',\n",
       "  'optical',\n",
       "  'character',\n",
       "  'recognition',\n",
       "  'frequently',\n",
       "  'excluded',\n",
       "  'things',\n",
       "  'considered',\n",
       "  'ai',\n",
       "  'become',\n",
       "  'routine',\n",
       "  'technology',\n",
       "  'artificial',\n",
       "  'intelligence',\n",
       "  'founded',\n",
       "  'academic',\n",
       "  'discipline',\n",
       "  'years',\n",
       "  'since',\n",
       "  'experienced',\n",
       "  'several',\n",
       "  'waves',\n",
       "  'optimism',\n",
       "  'followed',\n",
       "  'disappointment',\n",
       "  'loss',\n",
       "  'funding',\n",
       "  'known',\n",
       "  'ai',\n",
       "  'winter',\n",
       "  'followed',\n",
       "  'new',\n",
       "  'approaches',\n",
       "  'success',\n",
       "  'renewed',\n",
       "  'funding',\n",
       "  'ai',\n",
       "  'research',\n",
       "  'tried',\n",
       "  'discarded',\n",
       "  'many',\n",
       "  'different',\n",
       "  'approaches',\n",
       "  'lifetime',\n",
       "  'including',\n",
       "  'simulating',\n",
       "  'brain',\n",
       "  'modeling',\n",
       "  'human',\n",
       "  'problem',\n",
       "  'solving',\n",
       "  'formal',\n",
       "  'logic',\n",
       "  'large',\n",
       "  'databases',\n",
       "  'knowledge',\n",
       "  'imitating',\n",
       "  'animal',\n",
       "  'behavior',\n",
       "  'first',\n",
       "  'decades',\n",
       "  'st',\n",
       "  'century',\n",
       "  'highly',\n",
       "  'mathematical',\n",
       "  'statistical',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'dominated',\n",
       "  'field',\n",
       "  'technique',\n",
       "  'proved',\n",
       "  'highly',\n",
       "  'successful',\n",
       "  'helping',\n",
       "  'solve',\n",
       "  'many',\n",
       "  'challenging',\n",
       "  'problems',\n",
       "  'throughout',\n",
       "  'industry',\n",
       "  'academia',\n",
       "  'various',\n",
       "  'sub',\n",
       "  'fields',\n",
       "  'ai',\n",
       "  'research',\n",
       "  'centered',\n",
       "  'around',\n",
       "  'particular',\n",
       "  'goals',\n",
       "  'use',\n",
       "  'particular',\n",
       "  'tools',\n",
       "  'traditional',\n",
       "  'goals',\n",
       "  'ai',\n",
       "  'research',\n",
       "  'include',\n",
       "  'reasoning',\n",
       "  'knowledge',\n",
       "  'representation',\n",
       "  'planning',\n",
       "  'learning',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'perception',\n",
       "  'ability',\n",
       "  'move',\n",
       "  'manipulate',\n",
       "  'objects',\n",
       "  'general',\n",
       "  'intelligence',\n",
       "  'ability',\n",
       "  'solve',\n",
       "  'arbitrary',\n",
       "  'problem',\n",
       "  'among',\n",
       "  'field',\n",
       "  'long',\n",
       "  'term',\n",
       "  'goals',\n",
       "  'solve',\n",
       "  'problems',\n",
       "  'ai',\n",
       "  'researchers',\n",
       "  'use',\n",
       "  'versions',\n",
       "  'search',\n",
       "  'mathematical',\n",
       "  'optimization',\n",
       "  'formal',\n",
       "  'logic',\n",
       "  'artificial',\n",
       "  'neural',\n",
       "  'networks',\n",
       "  'methods',\n",
       "  'based',\n",
       "  'statistics',\n",
       "  'probability',\n",
       "  'economics',\n",
       "  'ai',\n",
       "  'also',\n",
       "  'draws',\n",
       "  'upon',\n",
       "  'computer',\n",
       "  'science',\n",
       "  'psychology',\n",
       "  'linguistics',\n",
       "  'philosophy',\n",
       "  'many',\n",
       "  'fields',\n",
       "  'field',\n",
       "  'founded',\n",
       "  'assumption',\n",
       "  'human',\n",
       "  'intelligence',\n",
       "  'precisely',\n",
       "  'described',\n",
       "  'machine',\n",
       "  'made',\n",
       "  'simulate',\n",
       "  'e',\n",
       "  'raises',\n",
       "  'philosophical',\n",
       "  'arguments',\n",
       "  'mind',\n",
       "  'ethics',\n",
       "  'creating',\n",
       "  'artificial',\n",
       "  'beings',\n",
       "  'endowed',\n",
       "  'human',\n",
       "  'like',\n",
       "  'intelligence',\n",
       "  'issues',\n",
       "  'explored',\n",
       "  'myth',\n",
       "  'fiction',\n",
       "  'philosophy',\n",
       "  'since',\n",
       "  'antiquity',\n",
       "  'science',\n",
       "  'fiction',\n",
       "  'futurology',\n",
       "  'also',\n",
       "  'suggested',\n",
       "  'enormous',\n",
       "  'potential',\n",
       "  'power',\n",
       "  'ai',\n",
       "  'may',\n",
       "  'become',\n",
       "  'existential',\n",
       "  'risk',\n",
       "  'humanity',\n",
       "  'thought',\n",
       "  'capable',\n",
       "  'artificial',\n",
       "  'beings',\n",
       "  'appeared',\n",
       "  'storytelling',\n",
       "  'devices',\n",
       "  'antiquity',\n",
       "  'common',\n",
       "  'fiction',\n",
       "  'mary',\n",
       "  'shelley',\n",
       "  'frankenstein',\n",
       "  'karel',\n",
       "  'apek',\n",
       "  'r',\n",
       "  'u',\n",
       "  'r',\n",
       "  'study',\n",
       "  'mechanical',\n",
       "  'formal',\n",
       "  'reasoning',\n",
       "  'began',\n",
       "  'philosophers',\n",
       "  'mathematicians',\n",
       "  'antiquity',\n",
       "  'study',\n",
       "  'mathematical',\n",
       "  'logic',\n",
       "  'led',\n",
       "  'directly',\n",
       "  'alan',\n",
       "  'turing',\n",
       "  'theory',\n",
       "  'computation',\n",
       "  'suggested',\n",
       "  'machine',\n",
       "  'shuffling',\n",
       "  'symbols',\n",
       "  'simple',\n",
       "  'could',\n",
       "  'simulate',\n",
       "  'conceivable',\n",
       "  'act',\n",
       "  'mathematical',\n",
       "  'deduction',\n",
       "  'insight',\n",
       "  'digital',\n",
       "  'computers',\n",
       "  'simulate',\n",
       "  'process',\n",
       "  'formal',\n",
       "  'reasoning',\n",
       "  'known',\n",
       "  'church',\n",
       "  'turing',\n",
       "  'thesis',\n",
       "  'church',\n",
       "  'turing',\n",
       "  'thesis',\n",
       "  'along',\n",
       "  'concurrent',\n",
       "  'discoveries',\n",
       "  'neurobiology',\n",
       "  'information',\n",
       "  'theory',\n",
       "  'cybernetics',\n",
       "  'led',\n",
       "  'researchers',\n",
       "  'consider',\n",
       "  'possibility',\n",
       "  'building',\n",
       "  'electronic',\n",
       "  'brain',\n",
       "  'first',\n",
       "  'work',\n",
       "  'generally',\n",
       "  'recognized',\n",
       "  'ai',\n",
       "  'mccullouch',\n",
       "  'pitts',\n",
       "  'formal',\n",
       "  'design',\n",
       "  'turing',\n",
       "  'complete',\n",
       "  'artificial',\n",
       "  'neurons',\n",
       "  'field',\n",
       "  'ai',\n",
       "  'research',\n",
       "  'born',\n",
       "  'workshop',\n",
       "  'dartmouth',\n",
       "  'college',\n",
       "  'term',\n",
       "  'artificial',\n",
       "  'intelligence',\n",
       "  'coined',\n",
       "  'john',\n",
       "  'mccarthy',\n",
       "  'distinguish',\n",
       "  'field',\n",
       "  'cybernetics',\n",
       "  'escape',\n",
       "  'influence',\n",
       "  'cyberneticist',\n",
       "  'norbert',\n",
       "  'wiener',\n",
       "  'attendees',\n",
       "  'allen',\n",
       "  'newell',\n",
       "  'cmu',\n",
       "  'herbert',\n",
       "  'simon',\n",
       "  'cmu',\n",
       "  'john',\n",
       "  'mccarthy',\n",
       "  'mit',\n",
       "  'marvin',\n",
       "  'minsky',\n",
       "  'mit',\n",
       "  'arthur',\n",
       "  'samuel',\n",
       "  'ibm',\n",
       "  'became',\n",
       "  'founders',\n",
       "  'leaders',\n",
       "  'ai',\n",
       "  'research',\n",
       "  'students',\n",
       "  'produced',\n",
       "  'programs',\n",
       "  'press',\n",
       "  'described',\n",
       "  'astonishing',\n",
       "  'computers',\n",
       "  'learning',\n",
       "  'checkers',\n",
       "  'strategies',\n",
       "  'c',\n",
       "  'reportedly',\n",
       "  'playing',\n",
       "  'better',\n",
       "  'average',\n",
       "  'human',\n",
       "  'solving',\n",
       "  'word',\n",
       "  'problems',\n",
       "  'algebra',\n",
       "  'proving',\n",
       "  'logical',\n",
       "  'theorems',\n",
       "  'logic',\n",
       "  'theorist',\n",
       "  'first',\n",
       "  'run',\n",
       "  'c',\n",
       "  'speaking',\n",
       "  'english',\n",
       "  'middle',\n",
       "  'research',\n",
       "  'u',\n",
       "  'heavily',\n",
       "  'funded',\n",
       "  'department',\n",
       "  'defense',\n",
       "  'laboratories',\n",
       "  'established',\n",
       "  'around',\n",
       "  'world',\n",
       "  'ai',\n",
       "  'founders',\n",
       "  'optimistic',\n",
       "  'future',\n",
       "  'herbert',\n",
       "  'simon',\n",
       "  'predicted',\n",
       "  'machines',\n",
       "  'capable',\n",
       "  'within',\n",
       "  'twenty',\n",
       "  'years',\n",
       "  'work',\n",
       "  'man',\n",
       "  'marvin',\n",
       "  'minsky',\n",
       "  'agreed',\n",
       "  'writing',\n",
       "  'within',\n",
       "  'generation',\n",
       "  'problem',\n",
       "  'creating',\n",
       "  'artificial',\n",
       "  'intelligence',\n",
       "  'substantially',\n",
       "  'solved',\n",
       "  'failed',\n",
       "  'recognize',\n",
       "  'difficulty',\n",
       "  'remaining',\n",
       "  'tasks',\n",
       "  'progress',\n",
       "  'slowed',\n",
       "  'response',\n",
       "  'criticism',\n",
       "  'sir',\n",
       "  'james',\n",
       "  'lighthill',\n",
       "  'ongoing',\n",
       "  'pressure',\n",
       "  'us',\n",
       "  'congress',\n",
       "  'fund',\n",
       "  'productive',\n",
       "  'projects',\n",
       "  'u',\n",
       "  'british',\n",
       "  'governments',\n",
       "  'cut',\n",
       "  'exploratory',\n",
       "  'research',\n",
       "  'ai',\n",
       "  'next',\n",
       "  'years',\n",
       "  'would',\n",
       "  'later',\n",
       "  'called',\n",
       "  'ai',\n",
       "  'winter',\n",
       "  'period',\n",
       "  'obtaining',\n",
       "  'funding',\n",
       "  'ai',\n",
       "  'projects',\n",
       "  'difficult',\n",
       "  'early',\n",
       "  'ai',\n",
       "  'research',\n",
       "  'revived',\n",
       "  'commercial',\n",
       "  'success',\n",
       "  'expert',\n",
       "  'systems',\n",
       "  'form',\n",
       "  'ai',\n",
       "  'program',\n",
       "  'simulated',\n",
       "  'knowledge',\n",
       "  'analytical',\n",
       "  'skills',\n",
       "  'human',\n",
       "  'experts',\n",
       "  'market',\n",
       "  'ai',\n",
       "  'reached',\n",
       "  'billion',\n",
       "  'dollars',\n",
       "  'time',\n",
       "  'japan',\n",
       "  'fifth',\n",
       "  'generation',\n",
       "  'computer',\n",
       "  'project',\n",
       "  'inspired',\n",
       "  'u',\n",
       "  'british',\n",
       "  'governments',\n",
       "  'restore',\n",
       "  'funding',\n",
       "  'academic',\n",
       "  'research',\n",
       "  'however',\n",
       "  'beginning',\n",
       "  'collapse',\n",
       "  'lisp',\n",
       "  'machine',\n",
       "  'market',\n",
       "  'ai',\n",
       "  'fell',\n",
       "  'disrepute',\n",
       "  'second',\n",
       "  'longer',\n",
       "  'lasting',\n",
       "  'winter',\n",
       "  'began',\n",
       "  'ai',\n",
       "  'gradually',\n",
       "  'restored',\n",
       "  'reputation',\n",
       "  'late',\n",
       "  'early',\n",
       "  'st',\n",
       "  'century',\n",
       "  'finding',\n",
       "  'specific',\n",
       "  'solutions',\n",
       "  'specific',\n",
       "  'problems',\n",
       "  'logistics',\n",
       "  'data',\n",
       "  'mining',\n",
       "  'medical',\n",
       "  'diagnosis',\n",
       "  'ai',\n",
       "  'solutions',\n",
       "  'widely',\n",
       "  'used',\n",
       "  'behind',\n",
       "  'scenes',\n",
       "  'vague',\n",
       "  'narrow',\n",
       "  'focus',\n",
       "  'allowed',\n",
       "  'researchers',\n",
       "  'produce',\n",
       "  'verifiable',\n",
       "  'results',\n",
       "  'exploit',\n",
       "  'mathematical',\n",
       "  'methods',\n",
       "  'collaborate',\n",
       "  'fields',\n",
       "  'statistics',\n",
       "  'economics',\n",
       "  'mathematics',\n",
       "  'faster',\n",
       "  'computers',\n",
       "  'algorithmic',\n",
       "  'improvements',\n",
       "  'access',\n",
       "  'large',\n",
       "  'amounts',\n",
       "  'data',\n",
       "  'enabled',\n",
       "  'advances',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'perception',\n",
       "  'data',\n",
       "  'hungry',\n",
       "  'deep',\n",
       "  'learning',\n",
       "  'methods',\n",
       "  'started',\n",
       "  'dominate',\n",
       "  'accuracy',\n",
       "  'benchmarks',\n",
       "  'around',\n",
       "  'according',\n",
       "  'bloomberg',\n",
       "  'jack',\n",
       "  'clark',\n",
       "  'landmark',\n",
       "  'year',\n",
       "  'artificial',\n",
       "  'intelligence',\n",
       "  'number',\n",
       "  'software',\n",
       "  'projects',\n",
       "  'use',\n",
       "  'ai',\n",
       "  'within',\n",
       "  'google',\n",
       "  'increased',\n",
       "  'sporadic',\n",
       "  'usage',\n",
       "  'projects',\n",
       "  'clark',\n",
       "  'also',\n",
       "  'presents',\n",
       "  'factual',\n",
       "  'data',\n",
       "  'indicating',\n",
       "  'improvements',\n",
       "  'ai',\n",
       "  'since',\n",
       "  'supported',\n",
       "  'lower',\n",
       "  'error',\n",
       "  'rates',\n",
       "  'image',\n",
       "  'processing',\n",
       "  'tasks',\n",
       "  'attributes',\n",
       "  'increase',\n",
       "  'affordable',\n",
       "  'neural',\n",
       "  'networks',\n",
       "  'due',\n",
       "  'rise',\n",
       "  'cloud',\n",
       "  'computing',\n",
       "  'infrastructure',\n",
       "  'increase',\n",
       "  'research',\n",
       "  'tools',\n",
       "  'datasets',\n",
       "  'survey',\n",
       "  'one',\n",
       "  'five',\n",
       "  'companies',\n",
       "  'reported',\n",
       "  'incorporated',\n",
       "  'ai',\n",
       "  'offerings',\n",
       "  'processes',\n",
       "  'history',\n",
       "  'established',\n",
       "  'unifying',\n",
       "  'theory',\n",
       "  'paradigm',\n",
       "  'guided',\n",
       "  'ai',\n",
       "  'research',\n",
       "  'f',\n",
       "  'ai',\n",
       "  'research',\n",
       "  'divided',\n",
       "  'competing',\n",
       "  'sub',\n",
       "  'fields',\n",
       "  'often',\n",
       "  'failed',\n",
       "  'communicate',\n",
       "  'g',\n",
       "  'sub',\n",
       "  'fields',\n",
       "  'based',\n",
       "  'technical',\n",
       "  'considerations',\n",
       "  'particular',\n",
       "  'goals',\n",
       "  'e',\n",
       "  'g',\n",
       "  'robotics',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'use',\n",
       "  'particular',\n",
       "  'tools',\n",
       "  'logic',\n",
       "  'artificial',\n",
       "  'neural',\n",
       "  'networks',\n",
       "  'social',\n",
       "  'factors',\n",
       "  'e',\n",
       "  'g',\n",
       "  'particular',\n",
       "  'institutions',\n",
       "  'researchers',\n",
       "  'also',\n",
       "  'came',\n",
       "  'deep',\n",
       "  'philosophical',\n",
       "  'differences',\n",
       "  'led',\n",
       "  'different',\n",
       "  'approaches',\n",
       "  'ai',\n",
       "  'unprecedented',\n",
       "  'success',\n",
       "  'statistical',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'eclipsed',\n",
       "  'approaches',\n",
       "  'much',\n",
       "  'sources',\n",
       "  'especially',\n",
       "  'business',\n",
       "  'world',\n",
       "  'use',\n",
       "  'term',\n",
       "  'artificial',\n",
       "  'intelligence',\n",
       "  'mean',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'neural',\n",
       "  'networks',\n",
       "  'number',\n",
       "  'researchers',\n",
       "  'explored',\n",
       "  'connection',\n",
       "  'neurobiology',\n",
       "  'information',\n",
       "  'theory',\n",
       "  'cybernetics',\n",
       "  'approach',\n",
       "  'largely',\n",
       "  'abandoned',\n",
       "  'although',\n",
       "  'elements',\n",
       "  'would',\n",
       "  'revived',\n",
       "  'access',\n",
       "  'digital',\n",
       "  'computers',\n",
       "  'became',\n",
       "  'possible',\n",
       "  'mid',\n",
       "  'ai',\n",
       "  'research',\n",
       "  'began',\n",
       "  'explore',\n",
       "  'possibility',\n",
       "  'human',\n",
       "  'intelligence',\n",
       "  'could',\n",
       "  'reduced',\n",
       "  'symbol',\n",
       "  'manipulation',\n",
       "  'research',\n",
       "  'centered',\n",
       "  'three',\n",
       "  'institutions',\n",
       "  'carnegie',\n",
       "  'mellon',\n",
       "  'university',\n",
       "  'stanford',\n",
       "  'mit',\n",
       "  'described',\n",
       "  'one',\n",
       "  'developed',\n",
       "  'style',\n",
       "  'research',\n",
       "  'john',\n",
       "  'haugeland',\n",
       "  'named',\n",
       "  'symbolic',\n",
       "  'approaches',\n",
       "  'ai',\n",
       "  'good',\n",
       "  'old',\n",
       "  'fashioned',\n",
       "  'ai',\n",
       "  'gofai',\n",
       "  'symbolic',\n",
       "  'approaches',\n",
       "  'achieved',\n",
       "  'great',\n",
       "  'success',\n",
       "  'simulating',\n",
       "  'high',\n",
       "  'level',\n",
       "  'thinking',\n",
       "  'small',\n",
       "  'demonstration',\n",
       "  'programs',\n",
       "  'achieved',\n",
       "  'great',\n",
       "  'success',\n",
       "  'expert',\n",
       "  'systems',\n",
       "  'approaches',\n",
       "  'based',\n",
       "  'cybernetics',\n",
       "  'artificial',\n",
       "  'neural',\n",
       "  'networks',\n",
       "  'abandoned',\n",
       "  'pushed',\n",
       "  'background',\n",
       "  'researchers',\n",
       "  'convinced',\n",
       "  'symbolic',\n",
       "  'approaches',\n",
       "  'would',\n",
       "  'eventually',\n",
       "  'succeed',\n",
       "  'creating',\n",
       "  'machine',\n",
       "  'artificial',\n",
       "  'general',\n",
       "  'intelligence',\n",
       "  'considered',\n",
       "  'goal',\n",
       "  'field',\n",
       "  'progress',\n",
       "  'symbolic',\n",
       "  'ai',\n",
       "  'seemed',\n",
       "  'stall',\n",
       "  'many',\n",
       "  'believed',\n",
       "  'symbolic',\n",
       "  'systems',\n",
       "  'would',\n",
       "  'never',\n",
       "  'able',\n",
       "  'imitate',\n",
       "  'processes',\n",
       "  'human',\n",
       "  'cognition',\n",
       "  'especially',\n",
       "  'perception',\n",
       "  'robotics',\n",
       "  'learning',\n",
       "  'pattern',\n",
       "  'recognition',\n",
       "  'number',\n",
       "  'researchers',\n",
       "  'began',\n",
       "  'look',\n",
       "  'sub',\n",
       "  'symbolic',\n",
       "  'approaches',\n",
       "  'specific',\n",
       "  'ai',\n",
       "  'problems',\n",
       "  'sub',\n",
       "  'symbolic',\n",
       "  'methods',\n",
       "  'manage',\n",
       "  'approach',\n",
       "  'intelligence',\n",
       "  'without',\n",
       "  'specific',\n",
       "  'representations',\n",
       "  'knowledge',\n",
       "  'researchers',\n",
       "  'related',\n",
       "  'field',\n",
       "  'robotics',\n",
       "  'rodney',\n",
       "  'brooks',\n",
       "  'rejected',\n",
       "  'symbolic',\n",
       "  'ai',\n",
       "  'focused',\n",
       "  'basic',\n",
       "  'engineering',\n",
       "  'problems',\n",
       "  'would',\n",
       "  'allow',\n",
       "  'robots',\n",
       "  'move',\n",
       "  'survive',\n",
       "  'learn',\n",
       "  'environment',\n",
       "  'called',\n",
       "  'work',\n",
       "  'several',\n",
       "  'names',\n",
       "  'e',\n",
       "  'g',\n",
       "  'embodied',\n",
       "  'situated',\n",
       "  'behavior',\n",
       "  'based',\n",
       "  'developmental',\n",
       "  'h',\n",
       "  'work',\n",
       "  'revived',\n",
       "  'non',\n",
       "  'symbolic',\n",
       "  'point',\n",
       "  'view',\n",
       "  'early',\n",
       "  'cybernetics',\n",
       "  'researchers',\n",
       "  'coincided',\n",
       "  'development',\n",
       "  'embodied',\n",
       "  'mind',\n",
       "  'thesis',\n",
       "  'related',\n",
       "  'field',\n",
       "  'cognitive',\n",
       "  'science',\n",
       "  'idea',\n",
       "  'aspects',\n",
       "  'body',\n",
       "  'movement',\n",
       "  'perception',\n",
       "  'visualization',\n",
       "  'required',\n",
       "  'higher',\n",
       "  'intelligence',\n",
       "  'soft',\n",
       "  'computing',\n",
       "  'finds',\n",
       "  'solutions',\n",
       "  'problems',\n",
       "  'solved',\n",
       "  'complete',\n",
       "  'logical',\n",
       "  'certainty',\n",
       "  'approximate',\n",
       "  'solution',\n",
       "  'often',\n",
       "  'sufficient',\n",
       "  'soft',\n",
       "  'computing',\n",
       "  'approaches',\n",
       "  'ai',\n",
       "  'include',\n",
       "  ...]]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6fdfb502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('winter', 0.3759722411632538),\n",
       " ('ai', 0.3491349518299103),\n",
       " ('actually', 0.33578574657440186),\n",
       " ('programs', 0.3161846399307251),\n",
       " ('field', 0.3098253905773163),\n",
       " ('systems', 0.30423590540885925),\n",
       " ('data', 0.3011187016963959),\n",
       " ('often', 0.2987501621246338),\n",
       " ('machine', 0.2976626753807068),\n",
       " ('experience', 0.28699710965156555)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_words = word2vec.wv.most_similar('intelligence')\n",
    "sim_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4ae082ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('whether', 0.43519946932792664),\n",
       " ('fully', 0.4198515713214874),\n",
       " ('however', 0.41358375549316406),\n",
       " ('humans', 0.3742591142654419),\n",
       " ('c', 0.36555925011634827),\n",
       " ('software', 0.35991308093070984),\n",
       " ('drones', 0.35991284251213074),\n",
       " ('research', 0.3560183644294739),\n",
       " ('find', 0.34959396719932556),\n",
       " ('known', 0.34892621636390686)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_words = word2vec.wv.most_similar('machine')\n",
    "sim_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75e3e7c",
   "metadata": {},
   "source": [
    "### Google Pre_Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73a73294",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import gensim.downloader as api\n",
    "from gensim.models import KeyedVectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25f6cd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'GoogleNews-vectors-negative300.bin'\n",
    "model = KeyedVectors.load_word2vec_format(filename, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1211185f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.most_similar(\"Man\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b546789c",
   "metadata": {},
   "source": [
    "### Now You can play :)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441a5d9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
